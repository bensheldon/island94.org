<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Island94.org : A lost and found | Island94.org</title>

  <meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="wmTiNTppcVFjV_tHGHez8oMd4bqASjTDvUG8zIJwKaPCZiiV1hzI4C06P8aR3azTX4lUolLwBb2K1aFXiN2Q-A" />
  

  <link rel="alternate" type="application/rss+xml" title="Island94.org" href="https://island94.org/feed.xml">

  <link rel="stylesheet" href="/assets/application-39a1f2f7963cb72fa41194b70f3ff8033d1cbab7fae2f8cb78a801ed41144a6a.css" data-turbo-track="reload" />
  <script type="importmap" data-turbo-track="reload">{
  "imports": {
    "application": "/assets/application-962c5e7cf27f994bdd1d258cdf9ea6b030432b2f7bd4f3ddca08ef99383fa2f8.js",
    "popper": "/assets/popper-003a40d80fd205e1fa00da117d5bdc19720ba330706eaa17f9ba9513fa502304.js",
    "bootstrap": "/assets/bootstrap.min-4ecafa8f279d0b285b3d27ca02c7e5da187907efe2c38f83eb8b4c7d6aa151c4.js",
    "lunr": "/assets/lunr-f99b014c8a6f84586ea3c195936e9cc362e046b318239f33786855679a6b8294.js",
    "@hotwired/turbo-rails": "/assets/turbo.min-38d030897e3554a265d3a3b6bdf4fb7509b08197ba2b6e3761683c07e776c1bc.js",
    "@hotwired/stimulus": "/assets/stimulus.min-dd364f16ec9504dfb72672295637a1c8838773b01c0b441bd41008124c407894.js",
    "@hotwired/stimulus-loading": "/assets/stimulus-loading-3576ce92b149ad5d6959438c6f291e2426c86df3b874c525b30faad51b0d96b3.js",
    "controllers/application": "/assets/controllers/application-368d98631bccbf2349e0d4f8269afb3fe9625118341966de054759d96ea86c7e.js",
    "controllers": "/assets/controllers/index-2db729dddcc5b979110e98de4b6720f83f91a123172e87281d5a58410fc43806.js",
    "controllers/search_controller": "/assets/controllers/search_controller-1c839dad802fbbcac7f45100753997dfa82c2453ff1b036badede2d38baef4ff.js",
    "controllers/theme_controller": "/assets/controllers/theme_controller-b01c6e0aeebf1ccac6a41c8358c52557f90e26684cb43214dcef7b5b11213069.js",
    "search": "/assets/search-ddd6c6d0d2f91d8051c02d2b76c8c07937235fba085eb3ff25464fb4db3d8569.js"
  }
}</script>
<link rel="modulepreload" href="/assets/popper-003a40d80fd205e1fa00da117d5bdc19720ba330706eaa17f9ba9513fa502304.js">
<link rel="modulepreload" href="/assets/bootstrap.min-4ecafa8f279d0b285b3d27ca02c7e5da187907efe2c38f83eb8b4c7d6aa151c4.js">
<link rel="modulepreload" href="/assets/turbo.min-38d030897e3554a265d3a3b6bdf4fb7509b08197ba2b6e3761683c07e776c1bc.js">
<link rel="modulepreload" href="/assets/stimulus.min-dd364f16ec9504dfb72672295637a1c8838773b01c0b441bd41008124c407894.js">
<link rel="modulepreload" href="/assets/stimulus-loading-3576ce92b149ad5d6959438c6f291e2426c86df3b874c525b30faad51b0d96b3.js">
<script type="module">import "application"</script>

  <script type="text/javascript">
    function setTheme() {
      let theme = localStorage.getItem('theme');
      if (!["light", "dark"].includes(theme)) {
        theme = window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
      }
      document.documentElement.setAttribute('data-bs-theme', theme);
    }

    setTheme();
    document.addEventListener('turbo:load', setTheme);
  </script>

      <meta name="robots" content="noindex, follow">

</head>
<body data-controller="search">
  <nav class="navbar navbar-expand-lg navbar-light mb-2 flex-column">
  <div class="container">
    <a class="navbar-brand" href="/">Island94.org</a>
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
        <li class="nav-item"><a class="nav-link" href="/about">About</a></li>
        <li class="nav-item"><a class="nav-link" href="/archives">Archives</a></li>
        <li class="nav-item"><a class="nav-link" href="/tags">Tags</a></li>
        <li class="nav-item"><a class="nav-link" href="/feed.xml">RSS Feed <i class="bi bi-rss-fill"></i></a></li>

        <li class="nav-item py-2 py-lg-1 col-12 col-lg-auto">
          <div class="vr d-none d-lg-flex h-100 mx-lg-2 text-light-500"></div>
          <hr class="d-lg-none my-0 text-light-500">
        </li>

        <li class="nav-item dropdown" data-controller="theme">
          <button
            data-theme-target="switcher"
            class="btn btn-link nav-link dropdown-toggle"
            type="button"
            aria-expanded="false"
            data-bs-toggle="dropdown">
            <i data-theme-target="activeIcon" class="bi bi-circle-half"></i>
            <span data-theme-target="switcherText">Theme</span>
          </button>
          <ul class="dropdown-menu dropdown-menu-end">
            <li>
              <button
                type="button"
                class="dropdown-item"
                data-bs-theme-value="light"
                data-action="theme#switch"
                aria-pressed="false">
                <i class="bi bi-sun"></i> Light
              </button>
            </li>
            <li>
              <button
                type="button"
                class="dropdown-item"
                data-bs-theme-value="dark"
                data-action="theme#switch"
                aria-pressed="false">
                <i class="bi bi-moon-stars-fill"></i> Dark
              </button>
            </li>
            <li>
              <button
                type="button"
                class="dropdown-item"
                data-bs-theme-value="auto"
                data-action="theme#switch"
                aria-pressed="true">
                <i class="bi bi-circle-half"></i> Auto
              </button>
            </li>
          </ul>
        </li>

      </ul>

      <form id="search" class="d-flex" action="/search" method="get">
        <div class="input-group">
          <input data-search-target="input" data-action="input->search#syncInputs" id="search-box" class="form-control search" role="search" name="q" placeholder="Search" aria-label="Search" results="0" type="text" autocomplete="off">
          <button type="submit" class="btn btn-outline-secondary">
            <i class="bi bi-search"></i>
            <span class="visually-hidden">Search</span>
          </button>
        </div>
      </form>
    </div>
  </div>
  <div class="container">
    <div class="text-muted fst-italic">
      — Ben Sheldon's personal blog and <a href="/2012/04/a-commonplace-book">commonplace book</a>.
    </div>
  </div>
</nav>

  
  <div class="container container-body">
    

<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/04/recently-april-7-2025"><p>Recently, April 7, 2025</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-04-08T02:33:00Z" itemprop="datePublished">April 8, 2025</time>

        • Tagged <a href="/posts/tags/weeknotes">weeknotes</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <ul>
  <li>I had my last day at old job. I got locked out of all my GitHub accounts at noon on Friday. At 2pm I did a tour of a coworking space for my new job. We’re looking at several spaces between where I live (SF) and my cofounder (Oakland). Both of us are looking forward to regularly being in the same space with a big whiteboard adjacent to somehere nice to walk around outside.</li>
  <li>I helped publish the monthly April Newsletter for the Alliance of Civic Technologists. I’ve stepped back mostly to focus on website tasks, though I’m proud that the comms stuff I previously pushed on (“what if we just regularly re-published stuff from the network without committing to a lot of other words?”) seems to have been taken up. I also feel like my involvement has been good training for my conviction of like “the reason we’re doing it this way is because I’m responsible for it.” Not that I expected to defend a a five page website with Jekyll on GitHub pages in 2023 (when I put together with Bill Hunt and Molly McLeod), but the only way some people know how to engage is by aggressively wondering why you didn’t do it differently.</li>
  <li>I tried not to think about (new) work all weekend. Saturday we got up before 5am to volunteer at a Bay Bridge swim; we worked registration and body marking (TIL some people are immune to sharpie). We took a dip ourselves, cafe for breakfast, then farmer’s market, cleaned up at home, met friends for tea (one of whom I’m trying to recruit to work with me; so it goes now), then to the protest, then a wine bar where we picked up some more friends in civic tech, then a gallery showing for some other friends from the swim club, then scrambled eggs at home for dinner. Saturday! Sunday was more sedate of swim, cafe, walk to Trader Joes, a different wine bar where I found agreement with a neighbor that being run over by a car is one’s most likely fate in SF.</li>
  <li>I got up a <a href="https://www.linkedin.com/posts/bensheldon_charlotte-weiner-mba-24-opening-the-door-activity-7314062454370496512-xHcP">LinkedIn post</a> about my job change:
    <blockquote>
      <p>Today was my last day GitHub. I’m really proud of the last 3 years helping build and support the Rails and Ruby developer community inside of GitHub and beyond.</p>

      <p>I also couldn’t pass on the new opportunity to work again on improving America’s social safety net. It’s been 3 years since I left Code for America and I’m excited about new options that have opened up with tech, telephony, and AI. I’m optimistic that we can fully close the loop in assisting, advocating, and escalating for people throughout their welfare journey and achieve significantly higher approval rates than was possible before. And do so sustainably; that’s the challenge!</p>

      <p>Here’s a nice write-up about <a href="https://www.gsb.stanford.edu/experience/news-history/charlotte-weiner-mba-24-opening-door-billions-unclaimed-public-benefits">what my cofounder and I are hoping to achieve</a>.</p>
    </blockquote>
  </li>
  <li>I participated in totally normal global commerce by ordering a mechanical keyboard (75% Alice brown). It’s currently in Guangzhuo; we shall see what happens now.</li>
  <li>I finished reading <em>Polostan</em>. It’s better than his last… 4 books, despite containing the phrase “girls’ bottoms in riding breaches” two times too many. I started Naomi Novik’s <em>Spinning Silver</em>.</li>
  <li>I started playing “The Witcher 3” which is neither cozy nor casual. I don’t know how many of the Witcher books I read previously because all evidence points to it being prior to 2014 when Pantheon’s new-hire perk was a Kindle. Seems like there are more books now.</li>
  <li>We watched the White Lotus finale 🤷</li>
  <li>On my first day as CTO, I reviewed all of our seat-based SaaS costs. $8 here, $4 there, $15 jeez 🫠 I’m already annoyed that my former employer charges for Branch Protection rules to block force-pushes on <code>main</code> 🙃</li>
</ul>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/04/recently-april-2-2025"><p>Recently, April 2, 2025</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-04-02T14:27:00Z" itemprop="datePublished">April 2, 2025</time>

        • Tagged <a href="/posts/tags/recently">recently</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <ul>
  <li>I’ve been away from work for the past week hosting family, including a 9 and 11 year old. In that week, we did: Ferry Building Farmer’s Market, Exploratorium and Tactile Dome, Alcatraz, “Dear San Francisco” at Club Fugazi, swam in the Bay and at the YMCA, rode a cable car, rode some buses, walked the Golden Gate Bridge, hiked Muir Woods, ate House of Prime Rib, Mama’s, Fish, Tailor’s Son, and Cafe de Casa. We had the kids for a night so their parent’s could do Napa and overnight at Indian Springs. I dropped them off at the airport yesterday and it is blessedly quiet and cats are decompressing.</li>
  <li>For the kids we opened up The Big Bag of Quest Headsets that we have accumulated because Angelina works on them. Lots of charging and battery swapping and then Beat Saber. The kids also played <em>Threes</em> and <em>Tiny Wings</em> on iPhones.</li>
  <li>During downtime we watched through “Wolf King”, and I got to provide adult commentary of “do you think <em>they</em> are a werelord?” about everyone; I had fun.</li>
  <li>I finished reading <em>Wicked</em>; I won’t be doing the trilogy. I recluctantly started reading <em>Polostan</em>; the past several Neal Stephenson books have not been my thing but I am a suffering optimist.</li>
  <li>I started playing <em>Anodyne</em>. Please suggest casual uncomplicated metroidvanias and open-world wander-arounders.</li>
</ul>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/04/wide-models-and-active-record-custom-validation-contexts"><p>Wide Models and Active Record custom validation contexts</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-04-01T15:00:00Z" itemprop="datePublished">April 1, 2025</time>

        • Tagged <a href="/posts/tags/rails">Rails</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>This post is a brief description of a pattern I use a lot using when building features in Ruby on Rails apps and that I think needed a name:</p>

<p><strong>Wide Models</strong> have many attributes (columns in the database) that are updated in multiple places in the application, but not always all at once i.e. different forms will update different subsets of attributes on the same model.</p>

<p><em>How is that not a <a href="https://codeclimate.com/blog/7-ways-to-decompose-fat-activerecord-models">“fat model”</a>?</em></p>

<blockquote>
  <p>As you add more intrinsic complexity (read: features!) to your application, the goal is to spread it across a coordinated set of small, encapsulated objects (and, at a higher level, modules) just as you might spread cake batter across the bottom of a pan. Fat models are like the big clumps you get when you first pour the batter in. Refactor to break them down and spread out the logic evenly. Repeat this process and you’ll end up with a set of simple objects with well defined interfaces working together in a veritable symphony.</p>
</blockquote>

<p>I dunno. I’ve seen teams take Wide Models pretty far (80+ attributes in a model) while still maintaining cohesion and developer productivity. And I’ve seen the opposite where there is a profusion of tiny service objects and any functional change must be threaded not just through a model, view and controller but also a form object and a decorator and several command objects, or where there is large number of narrow models that all have to be joined or included nearly all of the time in the app—and it sucks to work with. I mean, find the right size for you and your team, but the main thrust here is that bigger doesn’t inherently mean worse.</p>

<p>This all came to mind while reading Paweł Świątkowski’s <a href="https://katafrakt.me/2025/02/05/validations-nature-commands/">“On validations and the nature of commands”</a>:</p>

<blockquote>
  <p>Recently I took part in a discussion about where to put validations. What jarred me was how some people inadvertently try to get all the validation in a one fell swoop, even though the things they validate are clearly not one family of problems.</p>
</blockquote>

<p>The post goes on to suggest differentiating between:</p>

<ul>
  <li>“input validation”, which I take to mean user-facing validation that is only necessary when the user is editing some fields concretely on a form in the app. Example: that an account’s email address is appropriately constructed.</li>
  <li>“domain checks”, which I take to mean as more fundamental invariants/constraints of the system. Example: that an account is uniquely identified by its email address.</li>
</ul>

<p>I didn’t entirely agree with this advice though:</p>

<blockquote>
  <p>In Rails world you could use <code>dry-validation</code> for input validations and ActiveRecord validation for domain checks. Another approach would be to heavily use form objects (input validation) and limit model validations to actual business invariants.</p>
</blockquote>

<p>My disagreement is because Active Record validations have a built-in feature to selectively apply validations: <a href="https://guides.rubyonrails.org/active_record_validations.html#on">Validation Contexts (the <code>on:</code> keyword)</a> and specifically <a href="https://guides.rubyonrails.org/active_record_validations.html#custom-contexts"><em>custom</em> validation contexts</a>:</p>

<blockquote>
  <p>You can define your own custom validation contexts for callbacks, which is useful when you want to perform validations based on specific scenarios or group certain callbacks together and run them in a specific context. A common scenario for custom contexts is when you have a multi-step form and want to perform validations per step.</p>
</blockquote>

<p>I use custom validation contexts <em>a lot</em>. I don’t intend for this to be a tutorial on custom validation contexts, but just to give a quick example:</p>

<ul>
  <li>Imagine you have an <code>Account</code> model</li>
  <li>A person can register for an account with just an email address so they can sign in with a magic link.</li>
  <li>An account holder can later add a password to their account if they want to optionally sign in with a password</li>
  <li>An account holder can later add a username to their account which will be displayed next to their posts and comments.</li>
</ul>

<p>You might set up the <code>Account</code> model validations like this:</p>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Account</span> <span class="o">&lt;</span> <span class="no">ApplicationRecord</span>
  <span class="n">validates</span> <span class="ss">:email</span><span class="p">,</span> <span class="ss">uniqueness: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">presence: </span><span class="kp">true</span>
  <span class="c1"># also set up uniqueness/not-null constraints in the database too</span>
  <span class="n">validates</span> <span class="ss">:email</span><span class="p">,</span> <span class="ss">email_structure: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">on: </span><span class="p">[</span><span class="ss">:signup_form</span><span class="p">,</span> <span class="ss">:update_email_form</span><span class="p">]</span>

  <span class="n">validates</span> <span class="ss">:password</span><span class="p">,</span> <span class="ss">password_complexity: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">allow_blank: </span><span class="kp">true</span>
  <span class="n">validates</span> <span class="ss">:password</span><span class="p">,</span> <span class="ss">presence: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">password_complexity: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">on: </span><span class="p">[</span><span class="ss">:add_password_form</span><span class="p">,</span> <span class="ss">:edit_password_form</span><span class="p">]</span>

  <span class="n">validates</span> <span class="ss">:username</span><span class="p">,</span> <span class="ss">uniqueness: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">allow_blank: </span><span class="kp">true</span>
  <span class="n">validates</span> <span class="ss">:username</span><span class="p">,</span> <span class="ss">presence: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">on: </span><span class="p">[</span><span class="ss">:add_username_form</span><span class="p">,</span> <span class="ss">:edit_username_form</span><span class="p">]</span>
<span class="k">end</span>
</code></pre></div></div>

<p>Note: it’s possible to add <em>custom</em> validation contexts on <code>before_validation</code> and <code>after_validation</code> callbacks, but not others like <code>before_save</code>, <code>after_commit</code>, etc. only take the non-custom callbacks like <code>on: :create</code>.</p>

<p>So to wrap it up: sure, maybe it can all go in the Active Record model.</p>


  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/03/recently-march-26-2025"><p>Recently, March 26, 2025</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-03-26T16:01:00Z" itemprop="datePublished">March 26, 2025</time>

    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <ul>
  <li>I am on a new work adventure. I gave my notice at GitHub and will be doing <a href="https://www.gsb.stanford.edu/experience/news-history/charlotte-weiner-mba-24-opening-door-billions-unclaimed-public-benefits">this</a>  full-time starting in April. The new job should be a nice combination of a cozy “this again” and some thrilling new.</li>
  <li>I finished reading <em>Careless People</em>; recommend as a good sequence of business  trainwrecks that will leave you wondering if <em>this one</em> is penultimate trainwreck (spoiler: it’s not). Now I’m reading <em>Wicked</em>; I didn’t really like the beginning but it’s gotten more interesting.</li>
  <li>I finished <em>Severance</em>. Hopefully without spoilers, the consistent plot driver seems to be “Mark (yes) sucks”. So now just <em>White Lotus</em> and with palate cleansers of <em>Say Yes to the Dress</em>.</li>
  <li>I have been desultorily playing <a href="https://bracket.city/">Bracket City</a>; the scoring system generates no motivation for me but it’s fun to have found another use for the decades spent training my brain to parse deeply nested hierarchical syntax. I was also told that LinkedIn has games, and other than being “Faster than 95% of CEOs” at Queens, I have already lost my streak.</li>
  <li>I asked on Rails Performance Slack how to better delegate Rails model association accessors and got <a href="https://gist.github.com/bensheldon/2075bf807277697681c69f382fc96e9c">some good ideas</a>.</li>
  <li>My <a href="https://ruby.social/@bensheldon/114082492378628679">RailsConf session proposal</a> was accepted! See you there 🙌</li>
</ul>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/03/recently-march-16-2025"><p>Recently, March 16, 2025</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-03-16T22:37:00Z" itemprop="datePublished">March 16, 2025</time>

        • Tagged <a href="/posts/tags/recently">recently</a> and <a href="/posts/tags/weeknotes">weeknotes</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <ul>
  <li>We have promoted another cat to fostering: Merlin, the cat formerly known as Gray Cat.</li>
  <li>I finished the latest <em>Bruno, Chief of Police</em> book. I read it for the food and culture, but it has some bad descriptions of hacking in this one.  I started <em>The Midnight Library</em>, which as close as you can imagine to a TED talk but actually a novel. Next is <em>Careless People</em>, which I’m looking forward to; hopefully as exhilarating/vicariously-traumatic as <em>Exit Interview</em>.</li>
  <li>At work the latest is that all planning must snap to 1-month objectives. “If you don’t produce a plan, someone will produce one for you” is an advice. Super proud of the work: doing Pitchfork, kicking the tires on <code>ruby/json</code>, adding more knobs to Active Record. My Incident Commander shift was this week too; 2pm - 8pm really destroys the possibility of pre-dinner errands. I did go to a Mustqche Harbor show while on secondary Friday night and nothing bad happened (though I was still 15 minutes from home should something have).</li>
  <li>I bought a RailsConf supporter ticket. I submitted a panel discussion talk, so even if that’s accepted, I think I’ll still need a ticket. It’s for a good cause.</li>
  <li>Some new Playdate games. <em>Echo: The Oracle’s Scroll</em> was the only one I’ve beaten so far, despite fiddly jumping puzzle, and the surprise ending by which I mean I was surprised when I went to chat with an owl-person and then the credits rolled.</li>
  <li>I am recovering from pink eye, again. Reinfecting yourself is a thing that can happen. The last six months or so have not been my favorite, minor ailments-wise.</li>
  <li>Folks on Rails Performance Slack asked about Cursor rules, which was an opportunity for me to <a href="https://gist.github.com/bensheldon/00c23699bfb1857acbc2e9225de8adb1">consolidate mine</a> from several projects. I dunno, it’s ok.</li>
  <li>After about a month, I think I’m an iPad Mini person. The screen is very not good, but I guess “the best screen is the screen you have” when said screen is bigger than a phone, but smaller than 11 inches.</li>
  <li><a href="https://sfrecpark.org/CivicAlerts.aspx?AID=2127">This</a> is the most SF press release and I can’t wait.</li>
</ul>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/03/addressing-it-directly"><p>Addressing it directly</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-03-16T21:46:00Z" itemprop="datePublished">March 16, 2025</time>

    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>Lost to time in my Code for America email’s sent folder was a list of reasons why deferring to software engineers can be problematic. It included this theme, from Will Larson’s <a href="https://lethain.com/building-prestige/$0">“Building personal and organizational prestige”</a>:</p>

<blockquote>

  <p>In my experience, engineers confronted with a new problem often leap to creating a system to solve that problem rather than addressing it directly. I’ve found this particularly true when engineers approach a problem domain they don’t yet understand well, including building prestige.</p>

  <p>For example, when an organization decides to invest into its engineering brand, the initial plan will often focus on project execution. It’ll include a goal for publishing frequency, ensuring content is representationally accurate across different engineering sub-domains, and how to incentivize participants to contribute. If you follow the project plan carefully, you will technically have built an engineering brand, but my experience is that it’ll be both more work and less effective than a less systematic approach.</p>

</blockquote>

<p>Sometimes you just do stuff.</p>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/03/flattening-the-curve-for-the-safety-net"><p>Flattening the curve for the safety net, five years later</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-03-10T16:00:00Z" itemprop="datePublished">March 10, 2025</time>

    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p><em>It’s been 5 years since the start of the COVID-19 pandemic. From my notebook, I found a brief presentation I gave at Code for America in April, 2020 about that first month of the pandemic and the positive impact that GetCalFresh had during the initial lockdown and economic turmoil. There’s a contemporary postscript at the end too.</em></p>

<p>The idea of flattening the curve is to create time and space to build up the system capacity and avoid a catastrophic failure leading to greater social disruption and deaths.</p>

<p><a href="/uploads/2025/flatten-curve/1.png"><img src="/uploads/2025/flatten-curve/1.png" alt="" /></a></p>

<p>Within the social safety net, like the healthcare system, there is a limited systemic capacity to help people. Within the social safety net, catastrophic failure is not only that people aren’t able to apply for or receive benefits because the systems to receive and process their applications are overloaded, but also that they lose trust in society and government entirely as a result.</p>

<p><a href="/uploads/2025/flatten-curve/2.png"><img src="/uploads/2025/flatten-curve/2.png" alt="" /></a></p>

<p>Demand for CalFresh / SNAP / Food Stamps has massively increased over the past month. Our digital assister, GetCalFresh.org, has seen 6x the number of applicants, with a peak of over 9,000 applications per day.</p>

<p><a href="/uploads/2025/flatten-curve/3.png"><img src="/uploads/2025/flatten-curve/3.png" alt="" /></a></p>

<p>The government and their contractors are beefing up the capacity of their own systems to deal with the increased volume but it’s taken them several weeks to marshal those resources.</p>

<p><a href="/uploads/2025/flatten-curve/4.png"><img src="/uploads/2025/flatten-curve/4.png" alt="" /></a></p>

<p>During this time period of massive demand, these government-managed systems have suffered, leading to client-facing error messages, timeouts and service degradations.</p>

<p><a href="/uploads/2025/flatten-curve/5.png"><img src="/uploads/2025/flatten-curve/5.png" alt="" /></a></p>

<p>GetCalFresh, independently operated by Code for America and funded by CDSS (California Department of Social Services) and private philanthropy, has been online, stable and accepting applications this entire time, giving CalFresh applicants a path for submitting their applications regardless of the stability or availability of the underlying government systems. GetCalFresh is able to accept and hold those applications until they can be successfully processed through the government systems, once their outage is fixed or during non-peak usage times like overnight.</p>

<p><a href="/uploads/2025/flatten-curve/6.png"><img src="/uploads/2025/flatten-curve/6.png" alt="" /></a></p>

<p>GetCalFresh is a fantastic resource for Californians. And we’re seeing heavy promotion of GetCalFresh, likely because of the quality and stability of our system.</p>

<p><a href="/uploads/2025/flatten-curve/7.png"><img src="/uploads/2025/flatten-curve/7.png" alt="" /></a></p>

<p>GetCalFresh is now assisting two-thirds of all statewide CalFresh applications.</p>

<p><a href="/uploads/2025/flatten-curve/8.png"><img src="/uploads/2025/flatten-curve/8.png" alt="" /></a></p>

<p>And we’re maybe starting to see the government systems stabilize. Over the past 3 days we’ve observed a decrease in error rates and an increase in stability when interfacing with these government systems, which should also be comparable to how applicants would experience these government websites too. This implies that the government is successfully growing their capacity to address the increased volume of applicants.</p>

<p><a href="/uploads/2025/flatten-curve/9.png"><img src="/uploads/2025/flatten-curve/9.png" alt="" /></a></p>

<p>GetCalFresh has been a critical resource in ensuring that people-in-need can get safety-net resources during this unprecedented pandemic and maintain trust between themselves, society, and government. 👍</p>

<hr />

<h3 id="postscript-2025">Postscript (2025)</h3>

<p>Here we are, 5 years later. Of what I remember of putting this presentation together, it came of a desperation to find a story, a meaning, to the grief and fear and exhaustion of that first month. It creates a narrative arc: that things were fucked, and through the specificity of our efforts, they became unfucked. I believe that discovering the tidy stories in what we have done is inarguably a necessary comfort. And such stories are, inarguably too, inadequate at giving certainty to what we must do next.</p>

<p>I’m immensely proud of what we accomplished during this time. It strengthens my conviction of what small, durable, cross-functional teams, supported by stable, well-funded organizations with long-term goals, can accomplish together. And every act and decision I see leading up to that, during the good times: every boring technology decision, every generalist full-stack hire, every retrospective and team norms and career ladder conversation… it was worth it, because we performed how we had previously practiced together: exemplary.</p>

<p>And what the fuck! I have to reflect on this in the contemporary context of DOGE and the gutting of 18F and USDS and everyone else and any sense of stability or generative capacity in our federal government and the trickle down it will have everywhere. My original presentation is rather bland in calling them “Government Systems” but in reality these are systems that have already been outsourced, for decades, to private enterprise. They fell over, badly. And us, some stupid nonprofit geeks playing house in silicon valley, we happened to be there to hold things together for 60 million Californians until the safety-net could be stood back up again. Whatever the fuck DOGE is doing is bad. To face the dangers of an uncertain world, we need more capacity in-house in government, not less. I am angry, still.</p>

<p>There’s so much more that must be done.</p>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/01/ruby-thread-contention-simply-gvl-queuing"><p>Ruby “Thread Contention” is simply GVL Queuing</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-01-30T22:43:00Z" itemprop="datePublished">January 30, 2025</time>

        • Tagged <a href="/posts/tags/ruby">Ruby</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>There’s been a ton of fantastic posts from Jean Boussier recently explaining <a href="https://byroot.github.io/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app.html">application shapes</a>, <a href="https://byroot.github.io/ruby/performance/2025/01/23/the-mythical-io-bound-rails-app.html">instrumenting the GVL (Global VM Lock)</a>, and <a href="https://byroot.github.io/ruby/performance/2025/01/29/so-you-want-to-remove-the-gvl.html">thoughts on removing the GVL</a>. They’re great reads!</p>

<p>For the longest time, I’ve misunderstood the phrase “thread contention”. It’s a little embarrassing that given I’m the author of GoodJob (👍) and a maintainer of Concurrent Ruby and have been doing Ruby and Rails stuff for more than a decade. But true.</p>

<p>I’ve been reading about thread contention for quite a while.</p>
<ul>
  <li>I was probably initially introduced to thread contention in Nate Berkopec’s <a href="https://www.speedshop.co/2020/05/11/the-ruby-gvl-and-scaling.html">Speedshop blog</a>.</li>
  <li>Thread contention came to the front of my mind from Maciej Mensfeld’s post about the <a href="https://mensfeld.pl/2022/01/reduce-your-method-calls-by-99-9-by-replacing-threadpass-with-queuepop/">problems with Thread.pass</a></li>
  <li>The hot discussion about Rail’s <a href="https://github.com/rails/rails/issues/50450">default puma thread count</a>.</li>
  <li>Ivo Anjo did a <a href="https://ivoanjo.me/blog/2023/07/23/understanding-the-ruby-global-vm-lock-by-observing-it/">fantastic deep dive into the GVL</a>.</li>
</ul>

<p>Through all of this, I perceived thread contention as <em>contention</em>: a struggle, a bunch of threads all elbowing each other to run and stomping all over each other in a an inefficient, disagreeable, disorganized dogpile. But that’s not what happens at all!</p>

<p>Instead: when you have any number of threads in Ruby, each thread waits in an orderly queue to be handed the Ruby GVL, then they gently hold the GVL until they graciously give it up or it’s politely taken from them, and then the thread goes to the back of the queue, where they patiently wait again.</p>

<p>That’s what “thread contention” is in Ruby: in-order queuing for the GVL. It’s not that wild.</p>

<h3 id="lets-go-deeper">Let’s go deeper</h3>

<p>I came to this realization when <a href="https://github.com/bensheldon/good_job/issues/1554">researching whether I should reduce GoodJob’s thread priority</a> (I did). This came up after some exploration at GitHub, my day job, where we have a maintenance background thread that would occasionally blow out our performance target for a particular web request if the background thread happened to run at the same time that the web server (Unicorn) was responding to the web request.</p>

<p>Ruby threads are OS (operating system) threads. And OS threads are preemptive, meaning the OS is responsible for switching CPU execution among active threads. But, Ruby controls its GVL. Ruby itself takes a strong role in determining which threads are active for the OS by choosing which Ruby thread to hand the GVL to and when to take it back.</p>

<p>(Aside: Ruby 3.3 introduced M:N threads which decouples how Ruby threads map to OS threads, but ignore that wrinkle here.)</p>

<p>There’s a very good C-level explanation of what happens inside the Ruby VM in <a href="https://ruby-hacking-guide.github.io/thread.html">The Ruby Hacking Guide</a>. But I’ll do my best to explain briefly here:</p>

<p>When you create a Ruby thread (<code>Thread.new</code>), that thread goes into the back of a queue in the Ruby VM. The thread waits until the threads ahead of it in the queue have their chance to use the GVL.</p>

<p>When the thread gets to the front of the queue and gets the GVL, the thread will start running its Ruby code until it gives up the GVL. That can happen for one of two reasons:</p>

<ul>
  <li>When the thread goes from executing Ruby to doing IO, it releases the GVL (usually; it’s mostly considered a bug in the IO library if it doesn’t). When the thread is done with its IO operation, the Thread goes to the back of the queue.</li>
  <li>When the thread has been executing for longer than the length of the thread “quantum”, the Ruby VM takes back the GVL and the thread steps to the back of the queue again.  The Ruby thread quantum default is 100ms (this is configurable via <code>Thread#priority</code> or <a href="https://bugs.ruby-lang.org/issues/20861">directly as of Ruby 3.4</a>).</li>
</ul>

<p>That second scenario is rather interesting. When a Ruby thread starts running, the Ruby VM uses yet another background thread (at the VM level) that sleeps for 10ms (the “tick”) and then checks how long the Ruby thread has been running for. If the thread has been running for longer then the length of the quantum, the Ruby VM takes back the GVL from the active thread (“preemption”) and gives the GVL to the next thread waiting in the GVL queue. The thread that was previously executing now goes to the back of the queue. In other words: the thread quantum determines how quickly threads shuffle through the queue and no less/faster than the tick.</p>

<p>That’s it! That’s what happens with Ruby thread contention. It’s all very orderly, it just might take longer than expected or desired.</p>

<h3 id="whats-the-problem">What’s the problem</h3>

<p>The dreaded “Tail Latency” of multithreaded behavior can happen, related to the Ruby Thread Quantum, when you have what might otherwise be a very short request, for example:</p>

<ul>
  <li>A request that could be 10ms because it’s making ten 1ms calls to Memcached/Redis to fetch some cached values and then returns them (IO-bound Thread)</li>
</ul>

<p>⠀…but when it’s running in a thread next to:</p>

<ul>
  <li>A request that takes 1,000ms and largely spends its time doing string manipulation, for example a background thread that is taking a bunch of complex hashes and arrays and serializing them into a payload to send to a metrics server. Or rendering slow/big/complex views for Turbo Broadcasts (CPU-bound Thread)</li>
</ul>

<p>In this scenario, the CPU-bound thread will be very greedy with holding the GVL and it will look like this:</p>

<ol>
  <li>IO-bound Thread: Starts 1ms network request and releases GVL</li>
  <li>CPU-bound Thread: Does 100ms of work on the CPU before the GVL is taken back</li>
  <li>IO-bound Thread: Gets GVL again and starts next 1ms network request and releases GVL</li>
  <li>CPU-bound Thread: Does 100ms of work on the CPU before the GVL is taken back</li>
  <li>Repeat … 8 more times…</li>
  <li>Now 1,000 ms later, the IO-bound Thread, which ideally would have taken 10ms is finally done. That’s not good!</li>
</ol>

<p>That’s the worse case in this simple scenario with only two threads. With more threads of different workloads, you have the potential to have even more of a problem. Ivo Anjo also <a href="https://ivoanjo.me/blog/2023/02/11/ruby-unexpected-io-vs-cpu-unfairness/">wrote about this too</a>. You could speed this up by lowering overall thread quantum, or by reducing the priority of the CPU-bound thread (which lowers the thread quantum). This would cause the CPU-bound thread to be more finely sliced, but because the minimum slice is governed by the tick (10ms) you’d never get below a theoretical maximum of 100ms for the IO-bound thread; 10x more than optimal.</p>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/01/living-parklife-with-rails-coming-from-jekyll"><p>Living Parklife with Rails, coming from Jekyll</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-01-06T00:12:00Z" itemprop="datePublished">January 6, 2025</time>

        • Tagged <a href="/posts/tags/meta">meta</a>, <a href="/posts/tags/jekyll">jekyll</a>, and <a href="/posts/tags/rails">rails</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>I recently migrated this blog from Jekyll to <a href="https://parklife.dev/">Ben Pickles’s Parklife</a> and Ruby on Rails, still hosted as a static website on GitHub Pages. I’m pretty happy with the experience.</p>

<p>I’m writing this not because I feel any sense of advocacy (do what you want!) but to write down the reasons for myself. Maybe they’ll rhyme for you.</p>

<p>Here’s this blog’s repo if you want to see: <a href="https://github.com/bensheldon/island94.org">https://github.com/bensheldon/island94.org</a></p>

<h3 id="background">Background</h3>

<p>I’ve been blogging here for 20 years and this blog has been through it all: Drupal, Wordpress, Middleman, Jekyll, and now Parklife+Rails.</p>

<p>For the past decade the blog has largely been in markdown files, which I don’t intend to change. Over the past 2 years I also exported 15 years of pinboard/del.icio.us bookmarks, and my Kindle book highlights into markdown-managed files too. I’ve also dialed in some <a href="https://island94.org/2024/1/trigger-github-actions-workflows-from-apple-shortcuts">GitHub Action and Apple Shortcut powered integrations</a>. I’m really happy with Markdown files in a git repo, scripted with Ruby.</p>

<p>…but there’s more than <em>just</em> Ruby.</p>
<h3 id="mastery">Mastery</h3>

<p>I’m heavily invested in the Ruby on Rails ecosystem. I think it’s fair to say I have mastery in Rails: I’m comfortable building applications with it, navigating and extending the framework code, intuiting the conceptual vision of the core team, and being involved in the life of the comunity where I’ve earned some positive social capital to spend as needed.</p>

<p>I don’t have that in Jekyll. I am definitely handy in Jekyll. I’ve built plugins, I’ve done some wild stuff with liquid. But I’m not involved with Jekyll in the everyday sense like I am with Rails. I <em>feel</em> that when I go to make changes to my blog. There’s a little bit of friction mentally switching over to liquid, and Jekyll’s particular utilities that are <em>similar to but not the same</em> as Action View and Active Support. Jekyll is great; it’s me and the complexity of my website that’s changed.</p>

<p>(I do still maintain some other Jekyll websites; no complaints elsewhere.)</p>

<h3 id="parklife-with-ruby-on-rails">Parklife with Ruby on Rails</h3>

<p>I hope I’m not diminishing <a href="https://parklife.dev/">Parklife</a> by writing that it isn’t functionally <em>much</em> more  than <code>wget</code>. It’s in Ruby and mounts+crawls a Rack-based web application, does a little bit to rewrite the base URLs, and spits out a directory of static HTML files. That’s it! It’s great!</p>

<p>It was pretty easy for me to make a lightweight Ruby on Rails app, that loaded up all my markdown-formatted content and frontmatter, and spat them out again as Controllers and ERB Views.</p>

<p>This blog is about 7k pages. For a complete website artifact:</p>

<ul>
  <li>Jekyll: takes about 20 seconds to build</li>
  <li>Parklife with Rails: takes about 20 seconds to build</li>
</ul>

<p>In addition to the productivity win for me of being able to work with the ERB and Action View helpers I’m familiar with, I also find my development loop with Parklife and Rails is <em>faster</em> than Jekyll: I don’t have to rebuild the entire application to see the result of a single code or template change. I use the Rails development server to develop, not involving Parklife at all. On my M1 MBP a cold boot of Rails takes less than a second, a code reload is less than 100ms, and most pages render in under 10ms.</p>

<p>With Jekyll, even with <code>--incremental</code>, most development changes required a 10+ second rebuild. Not my favorite.</p>

<h3 id="the-technically-novel-bits">The technically novel bits</h3>

<ol>
  <li>
    <p>if you want to trigger Rails code reload with any arbitrary set of files, like a directory of markdown files, you use <code>ActiveSupport::FileUpdateChecker</code> (which has a kind of complicated set of arguments):</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># config/application.rb</span>
<span class="nb">self</span><span class="p">.</span><span class="nf">reloaders</span> <span class="o">&lt;&lt;</span> <span class="no">ActiveSupport</span><span class="o">::</span><span class="no">FileUpdateChecker</span><span class="p">.</span><span class="nf">new</span><span class="p">([],</span> <span class="p">{</span>
  <span class="s2">"_posts"</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s2">"md"</span><span class="p">,</span> <span class="s2">"markdown"</span><span class="p">],</span>
  <span class="s2">"_bookmarks"</span> <span class="o">=&gt;</span> <span class="p">[</span><span class="s2">"md"</span><span class="p">,</span> <span class="s2">"markdown"</span><span class="p">],</span>
<span class="p">})</span> <span class="k">do</span>
  <span class="no">Rails</span><span class="p">.</span><span class="nf">application</span><span class="p">.</span><span class="nf">reload_routes!</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Each of my blog posts has a list of historical redirects stored in their frontmatter (a legacy of so many framework changes). I had to think about how to do a catch-all route to render a static meta-refresh template:</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># config/routes.rb</span>
<span class="no">Rails</span><span class="p">.</span><span class="nf">application</span><span class="p">.</span><span class="nf">routes</span><span class="p">.</span><span class="nf">draw</span> <span class="k">do</span>
  <span class="n">get</span> <span class="s2">"*path"</span><span class="p">,</span> <span class="ss">to: </span><span class="s2">"redirects#show"</span><span class="p">,</span> <span class="ss">constraints: </span><span class="o">-&gt;</span><span class="p">(</span><span class="n">req</span><span class="p">)</span> <span class="p">{</span> <span class="no">Redirect</span><span class="p">.</span><span class="nf">all</span><span class="p">.</span><span class="nf">key?</span> <span class="n">req</span><span class="p">.</span><span class="nf">path</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sr">%r{</span><span class="se">\A</span><span class="sr">/}</span><span class="p">,</span> <span class="s2">""</span><span class="p">).</span><span class="nf">sub</span><span class="p">(</span><span class="sr">%r{/</span><span class="se">\z</span><span class="sr">}</span><span class="p">,</span> <span class="s2">""</span><span class="p">)</span> <span class="p">}</span>
  <span class="c1"># ...all the other routes</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="in-conclusion">In conclusion</h3>

<p>Here’s <a href="https://github.com/bensheldon/island94.org/blob/main/Parkfile">this blog’s Parkfile</a>. I did a little bit of convenience monkeypatching of things I intend to contribute upstream to Parklife. I dunno, maybe you’ll like the Parklife too.</p>

  </div>
</article>
<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">
      <a class="post-link" href="/2025/01/how-im-thinking-about-ai-llms"><p>How I’m thinking about AI (LLMs)</p>
</a>
    </h1>
    <p class="post-meta text-muted">
        <time datetime="2025-01-05T22:49:00Z" itemprop="datePublished">January 5, 2025</time>

        • Tagged <a href="/posts/tags/ai">ai</a> and <a href="/posts/tags/opinions">opinions</a>
    </p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <p>With AI, in my context we’re talking about LLMs (Large Language Models), which I simplify down to “text generator”: they take text as input, and they output text.</p>

<p>I wrote this to share with some folks I’m collaborating with on building AI-augmented workflows. I’ve struggled to find something that is both condensed and whose opinionations match my own. So I wrote it myself.</p>

<p>The following explanation is intended to be accurate, but not particularly precise.  For example, there is ChatGPT the product, there is an LLM at the bottom, and then in the middle there are other functions and capabilities. Or Claude or AWS Nova or Llama. These things are more than <em>*just*</em> LLMs, but they are also <em>not much</em> more than an LLM. Some of these tools can also interpret images and documents and audio and video. To do so, they’re passing those documents through specialized functions like OCR (optical character recognition), voice-recognition and image-recognition tools and then those results are turned into more text input. And some of them can take “Actions” with “Agents” which is still based on text output, just being structured and fed into something else. It’s text text text.</p>

<p>(also, if something is particularly wrong, let me know please)</p>

<h3 id="a-little-about-llms">A little about LLMs</h3>

<p>The language around LLMs and “AI” is fucked up with hype and inappropriate metaphors. But the general idea is there is two key phases to keep track of:</p>

<ol>
  <li>Training: Baking the model. At which point it’s done. I don’t know anyone who is actually building models Everyone is using something like OpenAI or Claude or Llama. And even while these things can be “fine tuned” I don’t know anyone doing it; operating at the model level requires input data on the order of tens of thousands of inputs/examples.</li>
  <li>Prompting: Using the model, giving input and getting output. This is everything the vast majority of developers are doing.</li>
</ol>

<p>That’s it. Those are the only two buckets you need to think about.</p>

<h4 id="1-training">1. Training</h4>

<p>The way AI models get made is to first collect trillions of pages of written text (an example is <a href="https://commoncrawl.org/">Common Crawl</a> which scrapes the Internet). Then use machine learning to identify probabilistic patterns that can be represented by only several billion variables (floating point numbers). This is called <strong>“Pre Training”</strong>. At this point, you can say “Based on the input data, it’s probabilistically likely that the word after “eeny meany miney” is “moe”.</p>

<p>Then there is the phase of <strong>“Fine Tuning”</strong> which makes sure that longer strings of text input are completed in ways that are intended (never right or wrong, just intended or expected). For example, if the text input is “Write me a Haiku about frogs” you expect a short haiku about frogs and not a treatise on the magic of the written word or amphibians. Fine tuning is largely accomplished by tens of thousands of workers in Africa and South Asia reading examples of inputs and outputs and clicking 👍 or 👎 on their screen. This is then fed back into machine learning models to say, of the billion variables, which variables should get a little more or less oomph when they’re calculating the output. Fine Tuning requires tens of thousands of these scored examples; again, this is probabilistic-scale stuff. This can also be called <strong>RLHF (Reinforcement Learning from Human Feedback)</strong>, though that sometimes also refers to few-shot prompting, which is Prompt-phase (“Learning” is a nonsense word in the AI domain; it has zero salience without clarifying which phase you’re talking about). A lot of the interesting fine-tuning, imo, comes from getting these text generators to:</p>

<ul>
  <li>Read like a human chatting with you, rather than textual diarrhea</li>
  <li>Getting structured output, like valid JSON, rather than textual diarrhea</li>
</ul>

<p>Note: You can mentally slot in words like “parameters”, “dimensions”, “weights” and “layers” into all this. Also whenever someone says “we don’t really know how they work” what they really mean is “there’s a lot of variables and I didn’t specifically look at them all”. But that’s no different than being given an Excel spreadsheet with several VLOOKUPS and functions and saying “sure, that looks ok” and copy-pasting the report on to your boss; I mean, you <em>could</em> figure it all out, but it seems to work and you’re a busy person.</p>

<p>Ok, now we’re done with training. The model at this point is baked and no further modification takes place: no memory, no storage, no “learning” in the sense of a biological process. From this point further they operate as a function: input in, output out, no side effects.</p>

<p>Here’s how AWS Bedrock, which is how I imagine lots of companies are using AI in their product, <a href="https://docs.aws.amazon.com/bedrock/latest/userguide/data-protection.html">describes all this</a>:</p>

<blockquote>
  <p>After delivery of a model from a model provider [Anthropic, OpenAI, Meta] to AWS, Amazon Bedrock will perform a deep copy of a model provider’s inference and training software into those accounts for deployment. Because the model providers don’t have access to those accounts, they don’t have access to Amazon Bedrock logs or to customer prompts and completions.</p>
</blockquote>

<p>See! It’s all just dead artifacts uploaded into S3, that are then loaded onto EC2 on-demand. A fancy lambda! Nothing more.</p>

<h4 id="2-prompting">2. Prompting</h4>

<p>Prompting is when we give the model input, and then it gives back some output. That’s it. Unless we are specifically collecting trillions of documents, or doing fine-tuning against thousands of examples (which we are NOT!), we are simply writing a prompt, and having the model generate some text based on it. It riffs. The output can be called “completions” because they’re just that: More words.</p>

<p>(Fun fact: how to get the LLM to <em>stop</em> writing words is a hard problem to solve)</p>

<p>Note: You might sometimes see prompting called model “testing” (as opposed to model building or training). That’s because you’re powering up the artifact to put some words through it. Testing testing is called “Evaluations” (“Evals” for short) and like all test test regimes the lukewarm debate I hear from everybody is “we aren’t but should we?”</p>

<h3 id="writing-prompts">Writing prompts</h3>

<p>This is the work! Unfortunately the language used to describe all of this is truly and totally fucked. By which I mean that words like “learning” and “thought” and “memory” and even “training” is reused again.</p>

<p>It’s all about simply writing a prompt that boops the resulting text generator output into the shape you want. It’s all snoot-booping, all the time.</p>

<p>Going back to the Training data, let’s make some conceptual distinctions:</p>

<ul>
  <li>Content: specific facts, statements and assertions that were (possibly) encoded into those billions of probabilities from the training data</li>
  <li>Structure: the overall probability that a string of words (really fragments of words) comes out again looking like something we expect, which has been adjusted via Fine Tuning</li>
</ul>

<p>Remember, this is just a probabilistic text generator. So there is probabilistic facts, and probabilistic structure. And that probabilistic part is why we have words like “hallucination” and “slop” and “safety”. There’s no there there. It’s just probabilities. There’s no guarantee that a particular fact has been captured in those billions of variables. It’s just a text generator. And it’s been trained on a lot of dumb shit people write. It’s <em>just</em> a text generator. Don’t trust it.</p>

<p>So on to some prompting strategies:</p>

<ul>
  <li><strong>Zero-Shot Prompting:</strong> This just means to ask something open-ended and the AI returns something that probabilistical follows:
    <blockquote>
      <p>Classify the sentiment of the following review as positive, neutral, or negative: “The quality is amazing, and it exceeded my expectations”</p>
    </blockquote>
  </li>
  <li><strong>Few-Shot (or one-shot/multi-shot) Prompting</strong>: This just means to provide one or more examples of “expected” completions in the prompt (remember, this is all prompt, not fine-tuning) to try to narrow down what could probabilistically follow:
    <blockquote>
      <p>Task: Classify the sentiment of the following reviews as positive, neutral, or negative.<br />
Examples:</p>
      <ol>
        <li>“I absolutely adore this product. It’s fantastic!” - positive</li>
        <li>“It’s okay, not the best I’ve used.” - neutral</li>
        <li>“This is terrible. I regret buying it.” - negative<br />
Now classify this review:</li>
        <li>“The quality is amazing, and it exceed my expectations” - [it’s blank, for the model to finish]</li>
      </ol>
    </blockquote>
  </li>
</ul>

<p><em>Note: Zero/One/Few/Multi-Shot is sometimes called “Learning” instead of “Prompting”. This is a terrible name, because there is no learning (the models are dead!) but is one of those things where the most assume-good-intent explanation is that over the course of the prompt and its incrementally generated completion that the output assumes the desired shape.</em></p>

<ul>
  <li><strong>Chain of Thought Prompting</strong>: The idea here is that the prompt includes a description of how a human might explain what they were doing to complete the prompt. And that boops the completion into filling out those steps, and arriving at a more expected answer:
    <blockquote>
      <p>Classify the sentiment of the following review as positive, neutral, or negative.<br />
“I absolutely adore this product. It’s fantastic!”<br />
Analysis 1: How does it describe the product?<br />
Analysis 2: How does it describe the functionality of the product?<br />
Analysis 3: How does it describe their relationship with the product?<br />
Analysis 4: How does it describe how friends, family, or others relate to the product?<br />
Overall: Is it positive, neutral, or negative?</p>
    </blockquote>
  </li>
</ul>

<p><em>Note: again, there is no “thought” happening. The point of the prompt is to boop the text completion into giving a more expected answer. There are some new models (as of late 2024) that are supposed to do Chain-of-Thought implicitly; afaik there is just a hidden/unshown prompt that says “break this down into steps” and an intermediate output that takes the output of that and feeds it into another hidden/unshown prompt and then the output of that is shown to you. That’s why they costs more, cause it’s invoking the the LLM twice on your behalf.</em></p>

<ul>
  <li><strong>Chain Prompting</strong>: This simply means that you take the output of one prompt, and then feed that into a new prompt. This can be useful to isolate a specific prompt and output. It might also be necessary because of the length: LLMs can only operate on so many words, so if you need to summarize a long document in a prompt, you’d need to first break it down into smaller chunks, use the LLM to summarize each chunk, and then combine the summaries into a new prompt for the LLM summarize that.</li>
  <li><strong>RAG (Retrieval Augmented Generation) Prompting</strong>: This means that you look up some info in a database, and then insert that into the prompt before handing it to the LLM. Everything is prompt, there is only prompt.</li>
</ul>

<p><em>Note: <strong>“Embeddings”</strong> are a way of search indexing your text. LLMs take all those trillions of documents and probabilistically boils them down to several billion variables. Embeddings boil down further to a couple thousand variables (floating point numbers). Creating an embedding means providing a piece of text, and you get back the values of those thousand floating point numbers that probabilistically describe that text (big brain idea: it is the document’s location in a thousand-dimensional space). That lets you compute across multiple documents “given this document within the n-dimensional space, what are its closest neighboring documents semantically/probabilistically?” Embeddings are useful when you want to do RAG Prompting to pull out relevant documents and insert their text into your prompt before it’s fed to the LLM to generate output.</em></p>

<ul>
  <li><strong>Cues and Nudges</strong> There are <a href="https://web.archive.org/web/20241112140504/https://news.ycombinator.com/item?id=40474716">certain phrases</a>, like “no yapping” or <a href="https://arstechnica.com/information-technology/2023/09/telling-ai-model-to-take-a-deep-breath-causes-math-scores-to-soar-in-study/">“take a deep breath”</a> that change the output. I don’t think there is anything delightful about this; it’s simply trying to boop up the variables you want in your output and words are the only inputs you have. I’m sure there will someday be better ways to do it, but whatever works.</li>
</ul>

<h3 id="a-strong-opinion-about-zero-shot-prompting">A strong opinion about zero-shot prompting</h3>

<p>Don’t do it! I think it’s totally fine if you just want to ask a question and try to intuit the extent that the model has been trained or tuned on the particular domain you’re curious about. But you should put ZERO stock in the answer as something factual.</p>

<p>If you need facts, you must provide the facts as part of your prompt. That means:</p>

<ul>
  <li>Providing a giant pile of text as content, or breaking it down (like via embeddings) and injecting smaller chunks via RAG</li>
  <li>Providing any and all input you ever expect to get out of the output</li>
</ul>

<p>It’s ok to summarize, extract, translate or sentiment. The only reason it’s ok to zero-shot code is because it’s machine verifiable (you run it). Otherwise, you must verify! Or don’t do it at all.</p>

  </div>
</article>


<hr>

<div class="d-flex justify-content-between mb-5">
    <a href="/posts/1" class="btn btn-outline-primary">Newer posts</a>
    <a href="/posts/3" class="btn btn-outline-primary">Older posts</a>
</div>

  </div>

</body>
</html>
